**Change Request: CR‑003 – Temporal MPG Dynamics, Full Potency Index & Noetic Hooks**

---

## 1. Objective

Extend CR‑001 (MPG prototype) and CR‑002 (SHAP‑backed RV detection + API) to:

1. Represent the **Mirrored Profile Graph as a time‑indexed hierarchy** \(MPG\_t\) with explicit “segment state” snapshots, consistent with the *Dynamics and extensibility* section (MPG\_t, localize → roll‑up → restructure → project down).  [oai_citation:0‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  
2. Implement the full **Impact Factors for Structural Rogue Variables** — Rate of Change, Breadth of Impact, Amplification, Emotional/Psychological load, Gate Leverage, and Robustness — and combine them into a **Potency Index** stored in Neo4j.  [oai_citation:1‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  
3. Provide **Noetic hooks**: basic integration between the Potency Index of RV segments and Noetic coherence measures, so Mirror Core can use RV potency as a meta‑control signal in the SORK‑N loop.  [oai_citation:2‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

This CR operationalizes the “Impact Factors for Structural Rogue Variables” paragraph and the time‑indexed MPG dynamics described in Section 4.1–4.2.  [oai_citation:3‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

---

## 2. Scope

### In scope

- Neo4j schema extensions:
  - `:SegmentState` nodes storing **time‑indexed RV metrics** per segment.
- Python scripts:
  - **(A)** Extend CR‑002’s SHAP pipeline to write `:SegmentState` snapshots.
  - **(B)** New script `scripts/mpg_potency_index.py` to:
    - compute **Impact Factors** from history + topology,
    - normalize them to [0,1],
    - compute **Potency Index**,
    - write Potency & factor components back to Neo4j.
- Minimal **Noetic integration hook**:
  - optional `coherence` field in `:SegmentState`,
  - helper to expose “high‑potency RVs during low coherence” for Mirror Core.

### Out of scope

- Full Noetic implementation or coherence computation itself (assume coherence values are produced by a separate Noetic service and written into `:SegmentState` or directly into Neo4j).  [oai_citation:4‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  
- Front‑end visualization (covered by API from CR‑002).

---

## 3. Neo4j schema extensions

### 3.1 New node label: `:SegmentState`

This represents a **temporal snapshot** of a given `:Segment` at time `t` (logical epoch, trial block, or timestamp), consistent with the time‑indexed MPG\_t described in the *Dynamics and extensibility* section.  [oai_citation:5‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

**Label**: `:SegmentState`  

**Properties** (all floats ∈ [0,1] unless stated):

- `id: string` – UUID
- `segment_id: string` – FK to `:Segment.id`
- `t: float | int` – time index (timestamp or epoch id)
- `rv: bool` – whether this segment was RV at this time
- `rv_score: float` – absolute Shapley contribution sₖ(x) at t
- `coherence: float` – optional Noetic coherence C(t) relevant to this segment (0–1)
- **Impact Factor components (raw, unnormalized):**
  - `roc: float` – Rate of Change
  - `boi: float` – Breadth of Impact
  - `amplification: float`
  - `affective_load: float`
  - `gate_leverage: float`
  - `robustness: float`
- `potency: float` – Potency Index at this time (0–1 after normalization)
- `meta: map<string, any>` – optional metadata (e.g., masking style id, task id)
- `created_at: datetime`

**Relationships**

- `(:Segment)-[:HAS_STATE]->(:SegmentState)`
- Optional: `(:SegmentState)-[:NEXT]->(:SegmentState)` to encode local temporal ordering.

**Constraint**

```cypher
CREATE CONSTRAINT segmentstate_id IF NOT EXISTS
FOR (s:SegmentState) REQUIRE s.id IS UNIQUE;
```

---

## 4. Design: metrics & Potency Index

Using the “Impact Factors for Structural Rogue Variables” description, we define computable approximations for each factor.  [oai_citation:6‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

Each factor is first computed in **raw units**, then scaled to [0,1] across all segments (per batch) before combining into Potency.

### 4.1 Rate of Change (RoC)

> “Rate of Change (RoC) tracks how quickly its error‑explaining power is growing, surfacing accelerating patterns early.”  [oai_citation:7‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

Implementation:

- For each segment `S`, get last `k` `:SegmentState` nodes (sorted by `t`), with `rv_score`.
- Compute **slope** of rv_score over time (simple linear regression or difference):

```text
RoC(S) = slope of rv_score(t) over last k points
       ≈ (rv_score_last - rv_score_first) / (t_last - t_first)
```

Negative values → decreasing impact; we clip at 0 for Potency (only growth matters).

### 4.2 Breadth of Impact (BoI)

> “Breadth of Impact (BoI) estimates how widely change could propagate by combining how many outcomes it touches with pathway reliability and, for vertical routes, the number of levels spanned and the strength of projected influence to priority outcomes.”  [oai_citation:8‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

Prototype approximation:

- For each `:Segment` S:
  - `deg_out` = number of outgoing edges from S to other segments.
  - `w_out_sum` = sum of their strengths.
  - `levels_spanned` = number of distinct `level` values reachable from S within radius 2 (optional).
- Raw BoI:

```text
BoI(S) = w_out_sum * (1 + log(1 + deg_out)) * (1 + 0.2 * levels_spanned)
```

### 4.3 Amplification

> “Amplification inspects loops within and around the structure, including cross-level loops, to gauge the potential for reciprocal reinforcement that can turn a local shift into a system-level swing.”  [oai_citation:9‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

Approximation:

- For each S, in the segment‑level graph G¹:
  - Count simple cycles of length ≤ L (e.g., 3) that include S.
  - Compute sum of edge strengths along those cycles.
- Raw Amplification:

```text
Ampl(S) = (#cycles_through_S) + 0.5 * (mean_cycle_strength_through_S)
```

If no cycles, Ampl = 0.

### 4.4 Emotional / Psychological load

> “The Emotional/Psychological dimension gauges affective load and influence on emotion-tagged nodes and events, rolled up when the candidate lives at a higher level.”  [oai_citation:10‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

Approximation:

- For each S, get member nodes `members` (from `Segment.members` array from CR‑001).
- For each member node v:
  - `valence_v` ∈ [-1,1]
  - `intensity_v` ∈ [0,1]
- Raw affective load:

```text
Affective(S) = mean_over_v ( |valence_v| * intensity_v )
```

Higher magnitude + intensity → higher emotional load.

### 4.5 Gate leverage

> “Gate leverage (how concentrated and controllable the entry/exit interfaces are).”  [oai_citation:11‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

Approximation (using Def. 3 boundary B_S):  [oai_citation:12‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

- For S at level 0:
  - `|VS|` = number of member nodes.
  - `|B_S|` = number of boundary nodes (nodes with edges crossing segment boundary).
- Gate concentration:

```text
gate_ratio = |B_S| / max(1, |VS|)
GateLeverage(S) = 1 - gate_ratio       # fewer gates → more leverage
```

We can further weight by centrality of gate nodes (optional).

For higher‑level segments, we approximate using the same formula but treat inter‑segment edges as gates.

### 4.6 Robustness

> “Robustness (confidence, stability across masks, and sensitivity to evidence decay).”  [oai_citation:13‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

Prototype:

- `Conf_avg(S)` = current `Segment.confidence`.
- `persist_rate(S)` = fraction of last k `:SegmentState` snapshots where `rv = true`.
- Raw Robustness:

```text
Robust(S) = 0.6 * Conf_avg(S) + 0.4 * persist_rate(S)
```

When multiple masking styles are available, we can add variance across masks as a penalty; for now we assume a single masking style.

### 4.7 Potency Index

After computing raw values for all segments:

1. For each factor F ∈ {RoC, BoI, Ampl, Affective, GateLeverage, Robust}, compute global min/max across segments and scale:

```text
F_norm(S) = (F(S) - min_F) / (max_F - min_F + ε)
```

2. Combine into Potency Index:

```text
Potency(S) = w_roc   * RoC_norm(S)
           + w_boi   * BoI_norm(S)
           + w_ampl  * Ampl_norm(S)
           + w_aff   * Affective_norm(S)
           + w_gate  * Gate_norm(S)
           + w_rob   * Robust_norm(S)
```

With initial weights, e.g.:

```text
w_roc = 0.2
w_boi = 0.2
w_ampl = 0.2
w_aff = 0.15
w_gate = 0.1
w_rob = 0.15
```

Potency is stored in `:SegmentState.potency` and optionally rolled up to `:Segment.potency_latest`.

---

## 5. Implementation A – extend SHAP RV pipeline to store SegmentState

Modify **CR‑002**’s `mpg_rv_shap_demo.py`:

1. Add `:SegmentState` schema and helper.

2. When we mark a segment as RV for a given SHAP run, also create a `SegmentState` with:

- `t` = run counter or timestamp,
- `rv = true`, `rv_score`,
- `coherence` if available (or null),
- impact factors initially set to 0 (will be filled by Potency script).

### 5.1 Example patch (core parts)

```python
# --- in mpg_rv_shap_demo.py ---

class MPGNeo4j:
    # ... existing methods ...

    def init_segmentstate_schema(self):
        q = """
        CREATE CONSTRAINT segmentstate_id IF NOT EXISTS
        FOR (s:SegmentState) REQUIRE s.id IS UNIQUE;
        """
        self.run(q)

    def create_segment_state(
        self,
        seg_id: str,
        t_value: float,
        rv: bool,
        rv_score: float,
        coherence: float | None = None,
    ):
        state_id = str(uuid.uuid4())
        q = """
        MATCH (s:Segment {id: $seg_id})
        CREATE (st:SegmentState {
            id: $id,
            segment_id: $seg_id,
            t: $t,
            rv: $rv,
            rv_score: $rv_score,
            coherence: $coherence,
            roc: 0.0,
            boi: 0.0,
            amplification: 0.0,
            affective_load: 0.0,
            gate_leverage: 0.0,
            robustness: 0.0,
            potency: 0.0,
            created_at: datetime(),
            demo: true
        })
        CREATE (s)-[:HAS_STATE]->(st)
        """
        self.run(
            q,
            seg_id=seg_id,
            id=state_id,
            t=t_value,
            rv=rv,
            rv_score=float(rv_score),
            coherence=coherence,
        )
        return state_id
```

In `main()` / init, call `db.init_segmentstate_schema()` once.

When SHAP RV detection runs, we choose a `t_value` (e.g., step index or Unix timestamp):

```python
def shap_rv_detection(...):
    # ...
    t_value = time.time()  # or epoch counter

    # After computing contrib for each feature:
    for j, contrib in enumerate(abs_contrib):
        seg_id = feature_to_seg[j]
        # create state for every segment (rv or not)
        is_rv = contrib >= threshold
        db.create_segment_state(
            seg_id=seg_id,
            t_value=t_value,
            rv=is_rv,
            rv_score=float(contrib),
            coherence=None,  # or fetch from Noetic layer
        )

        if is_rv:
            # as before: mark segment 'rv' for current snapshot
            # (optional, can leave to potency script)
            ...
```

Now each SHAP run contributes one `SegmentState` per segment, giving us MP G_t samples.

---

## 6. Implementation B – Potency computation script

Create `scripts/mpg_potency_index.py` that:

1. Loads segment graph & segment states from Neo4j.  
2. Computes Impact Factors per segment (using last `k` states).  
3. Normalizes factors and Potency.  
4. Writes updated factors back into the most recent `:SegmentState` for each segment and also updates `:Segment.potency_latest`.

### 6.1 Script

```python
"""
mpg_potency_index.py

CR-003: Temporal Impact Factors & Potency Index for RV segments.
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, List, Tuple
import uuid
import math
import statistics

from neo4j import GraphDatabase
import networkx as nx


# --- CONFIG ---

NEO4J_URI = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "password"   # adjust
HISTORY_K = 5                  # number of recent states for RoC/persistence
MAX_CYCLE_LEN = 3              # for amplification
EPS = 1e-8


# --- NEO4J CLIENT ---

class MPGNeo4j:
    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def close(self):
        self.driver.close()

    def run(self, query: str, **params):
        with self.driver.session() as session:
            return list(session.run(query, **params))

    # Segments and states --------------------

    def get_segments(self) -> List[Dict]:
        q = """
        MATCH (s:Segment)
        WHERE s.demo = true
        RETURN s
        """
        return [dict(r["s"]) for r in self.run(q)]

    def get_segment_states(self, seg_id: str, k: int) -> List[Dict]:
        q = """
        MATCH (:Segment {id: $id})-[:HAS_STATE]->(st:SegmentState)
        RETURN st
        ORDER BY st.t DESC
        LIMIT $k
        """
        return [dict(r["st"]) for r in self.run(q, id=seg_id, k=k)]

    def get_segment_graph(self) -> nx.DiGraph:
        """
        Returns DiGraph of segments for amplification & BoI calculations.
        """
        G = nx.DiGraph()

        # Nodes
        for s in self.get_segments():
            G.add_node(s["id"], **s)

        # Edges
        q = """
        MATCH (s:Segment)-[r]->(t:Segment)
        WHERE s.demo = true AND t.demo = true
        RETURN s.id AS src, t.id AS dst, type(r) AS rel_type, r.strength AS strength
        """
        for rec in self.run(q):
            G.add_edge(
                rec["src"],
                rec["dst"],
                rel_type=rec["type"],
                strength=float(rec["strength"] or 0.0),
            )
        return G

    def get_segment_members(self, seg_id: str) -> List[Dict]:
        """
        Return member nodes for a segment to compute affective load & gate leverage.
        Assumes Segment.members holds node ids.
        """
        q = """
        MATCH (s:Segment {id: $id})
        WITH s, s.members AS member_ids
        UNWIND member_ids AS mid
        MATCH (n:MPGNode {id: mid})
        RETURN n
        """
        return [dict(r["n"]) for r in self.run(q, id=seg_id)]

    def get_boundary_nodes(self, seg_id: str) -> List[str]:
        """
        Approximate Def. 3 boundary for a level-0 segment by node ids stored in members.
        """
        q = """
        MATCH (s:Segment {id: $id})
        WITH s, s.members AS member_ids
        UNWIND member_ids AS mid
        MATCH (n:MPGNode {id: mid})
        OPTIONAL MATCH (n)-[r]->(m:MPGNode)
        WHERE NOT m.id IN member_ids
        WITH n, collect(r) AS rs
        WHERE size(rs) > 0
        RETURN n.id AS id
        """
        return [r["id"] for r in self.run(q, id=seg_id)]

    def update_segmentstate_potency(
        self,
        state_id: str,
        roc: float,
        boi: float,
        ampl: float,
        aff: float,
        gate: float,
        robust: float,
        potency: float,
    ):
        q = """
        MATCH (st:SegmentState {id: $id})
        SET st.roc = $roc,
            st.boi = $boi,
            st.amplification = $ampl,
            st.affective_load = $aff,
            st.gate_leverage = $gate,
            st.robustness = $robust,
            st.potency = $potency
        """
        self.run(
            q,
            id=state_id,
            roc=float(roc),
            boi=float(boi),
            ampl=float(ampl),
            aff=float(aff),
            gate=float(gate),
            robust=float(robust),
            potency=float(potency),
        )

    def update_segment_latest_potency(self, seg_id: str, potency: float):
        q = """
        MATCH (s:Segment {id: $id})
        SET s.potency_latest = $p
        """
        self.run(q, id=seg_id, p=float(potency))

    def get_latest_state(self, seg_id: str) -> Dict | None:
        q = """
        MATCH (:Segment {id: $id})-[:HAS_STATE]->(st:SegmentState)
        RETURN st
        ORDER BY st.t DESC
        LIMIT 1
        """
        res = self.run(q, id=seg_id)
        return dict(res[0]["st"]) if res else None


# --- IMPACT FACTOR HELPERS ---

def rate_of_change(states: List[Dict]) -> float:
    if len(states) < 2:
        return 0.0
    # states ordered desc by t
    t_vals = [float(st["t"]) for st in reversed(states)]
    s_vals = [float(st.get("rv_score", 0.0)) for st in reversed(states)]
    dt = t_vals[-1] - t_vals[0]
    if abs(dt) < EPS:
        return 0.0
    return (s_vals[-1] - s_vals[0]) / dt


def persistence(states: List[Dict]) -> float:
    if not states:
        return 0.0
    rv_flags = [bool(st.get("rv", False)) for st in states]
    return sum(rv_flags) / len(rv_flags)


def breadth_of_impact(G: nx.DiGraph, seg_id: str) -> float:
    if seg_id not in G:
        return 0.0
    deg_out = G.out_degree(seg_id)
    w_out_sum = sum(
        d.get("strength", 0.0) for _, _, d in G.out_edges(seg_id, data=True)
    )
    # vertical span via neighbors up to distance 2
    levels = set()
    for node in nx.single_source_shortest_path_length(G, seg_id, cutoff=2).keys():
        levels.add(int(G.nodes[node].get("level", 1)))
    levels_spanned = max(levels) - min(levels) if levels else 0
    return w_out_sum * (1 + math.log1p(deg_out)) * (1 + 0.2 * levels_spanned)


def amplification(G: nx.DiGraph, seg_id: str, max_cycle_len: int = MAX_CYCLE_LEN) -> float:
    if seg_id not in G:
        return 0.0
    cycles = []
    for cycle in nx.simple_cycles(G):
        if seg_id in cycle and 2 <= len(cycle) <= max_cycle_len:
            cycles.append(cycle)

    if not cycles:
        return 0.0

    strengths = []
    for cycle in cycles:
        edges = list(zip(cycle, cycle[1:] + [cycle[0]]))
        s_sum = 0.0
        for u, v in edges:
            if G.has_edge(u, v):
                s_sum += G.edges[u, v].get("strength", 0.0)
        strengths.append(s_sum / len(edges) if edges else 0.0)

    return len(cycles) + 0.5 * (sum(strengths) / len(strengths))


def affective_load(member_nodes: List[Dict]) -> float:
    if not member_nodes:
        return 0.0
    vals = []
    for n in member_nodes:
        valence = float(n.get("valence", 0.0))
        intensity = float(n.get("intensity", 0.5))
        vals.append(abs(valence) * intensity)
    return sum(vals) / len(vals)


def gate_leverage(boundary_nodes: List[str], total_members: int) -> float:
    if total_members <= 0:
        return 0.0
    gate_ratio = len(boundary_nodes) / total_members
    return max(0.0, 1.0 - gate_ratio)


def robustness(conf_avg: float, persist: float) -> float:
    return 0.6 * conf_avg + 0.4 * persist


def normalize_factor(vals: Dict[str, float]) -> Dict[str, float]:
    if not vals:
        return {}
    vmin = min(vals.values())
    vmax = max(vals.values())
    if abs(vmax - vmin) < EPS:
        return {k: 0.0 for k in vals.keys()}
    return {k: (v - vmin) / (vmax - vmin) for k, v in vals.items()}


# --- MAIN POTENCY PIPELINE ---

def compute_potency():
    db = MPGNeo4j(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)
    try:
        segments = db.get_segments()
        if not segments:
            print("No segments found.")
            return

        G = db.get_segment_graph()

        # raw factor values per segment
        roc_raw = {}
        boi_raw = {}
        ampl_raw = {}
        aff_raw = {}
        gate_raw = {}
        rob_raw = {}

        latest_state_id: Dict[str, str] = {}
        latest_potency: Dict[str, float] = {}

        for s in segments:
            seg_id = s["id"]

            # history
            states = db.get_segment_states(seg_id, HISTORY_K)
            if not states:
                continue

            roc_val = max(0.0, rate_of_change(states))  # clip negative
            roc_raw[seg_id] = roc_val

            persist_val = persistence(states)

            # breadth & amplification
            boi_val = breadth_of_impact(G, seg_id)
            boi_raw[seg_id] = boi_val

            ampl_val = amplification(G, seg_id)
            ampl_raw[seg_id] = ampl_val

            # affective load & gate leverage from level-0 members
            members = db.get_segment_members(seg_id)
            aff_val = affective_load(members)
            aff_raw[seg_id] = aff_val

            boundary = db.get_boundary_nodes(seg_id)
            gate_val = gate_leverage(boundary, total_members=len(members))
            gate_raw[seg_id] = gate_val

            conf_avg = float(s.get("confidence", 0.5))
            rob_val = robustness(conf_avg, persist_val)
            rob_raw[seg_id] = rob_val

            # remember latest state
            latest = db.get_latest_state(seg_id)
            if latest:
                latest_state_id[seg_id] = latest["id"]

        # normalize each factor
        roc_norm = normalize_factor(roc_raw)
        boi_norm = normalize_factor(boi_raw)
        ampl_norm = normalize_factor(ampl_raw)
        aff_norm = normalize_factor(aff_raw)
        gate_norm = normalize_factor(gate_raw)
        rob_norm = normalize_factor(rob_raw)

        # combine into potency
        w_roc, w_boi, w_ampl, w_aff, w_gate, w_rob = 0.2, 0.2, 0.2, 0.15, 0.1, 0.15

        for seg_id in latest_state_id.keys():
            p = (
                w_roc * roc_norm.get(seg_id, 0.0)
                + w_boi * boi_norm.get(seg_id, 0.0)
                + w_ampl * ampl_norm.get(seg_id, 0.0)
                + w_aff * aff_norm.get(seg_id, 0.0)
                + w_gate * gate_norm.get(seg_id, 0.0)
                + w_rob * rob_norm.get(seg_id, 0.0)
            )
            latest_potency[seg_id] = p

        # write back into latest SegmentState and Segment
        for seg_id, state_id in latest_state_id.items():
            db.update_segmentstate_potency(
                state_id,
                roc=roc_raw.get(seg_id, 0.0),
                boi=boi_raw.get(seg_id, 0.0),
                ampl=ampl_raw.get(seg_id, 0.0),
                aff=aff_raw.get(seg_id, 0.0),
                gate=gate_raw.get(seg_id, 0.0),
                robust=rob_raw.get(seg_id, 0.0),
                potency=latest_potency.get(seg_id, 0.0),
            )
            db.update_segment_latest_potency(seg_id, latest_potency.get(seg_id, 0.0))

        print("Potency Index updated for", len(latest_potency), "segments.")
    finally:
        db.close()


if __name__ == "__main__":
    compute_potency()
```

Run:

```bash
python scripts/mpg_potency_index.py
```

---

## 7. Noetic hooks

The Noetic layer computes coherence measures across streams (correlation matrices, entropy changes, coherence spectra, calibrated probabilities of intuitive accuracy).  [oai_citation:14‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

For CR‑003 we add *lightweight hooks*:

1. `:SegmentState.coherence` (already in schema) should be filled by a **Noetic service** each time it computes a new coherence snapshot (e.g., for trials where this segment is most relevant).

2. Mirror Core can now query:

- “Top‑K segments with **high Potency** and **low coherence** in last window” → candidates for intervention, gating, or extra monitoring.

Example Cypher for Mirror Core:

```cypher
MATCH (s:Segment)-[:HAS_STATE]->(st:SegmentState)
WHERE st.coherence < 0.3
WITH s, st
ORDER BY st.potency DESC
LIMIT 10
RETURN s.id, s.name, st.potency, st.coherence;
```

This is directly aligned with the functional role of RVs in LAIZA — **early warning, prioritization, targeted action, learning & re‑coherence, governance** — described in Section 4.2.  [oai_citation:15‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

---

## 8. How to run CR‑003 end‑to‑end

1. **After CR‑002 is in place**, modify `mpg_rv_shap_demo.py` as in Implementation A, then run it multiple times (over different data batches / sessions) to populate `:SegmentState` history.

2. Run:

```bash
python scripts/mpg_potency_index.py
```

3. Inspect in Neo4j:

```cypher
MATCH (s:Segment {demo:true})-[:HAS_STATE]->(st:SegmentState)
RETURN s.id, s.name, st.t, st.rv, st.rv_score, st.potency
ORDER BY st.t DESC;
```

4. Use the existing API from CR‑002 (or add a `/segment_states` endpoint) to visualize potency over time, e.g., as a time series per segment.

---

## 9. Acceptance criteria

CR‑003 is complete when:

1. **Temporal MPG representation**
   - `:SegmentState` nodes exist, linked via `(:Segment)-[:HAS_STATE]->(:SegmentState)`, with proper `t` and `rv_score` values.

2. **Impact factor computation**
   - `mpg_potency_index.py` runs successfully and:
     - computes non‑trivial `roc`, `boi`, `amplification`, `affective_load`, `gate_leverage`, `robustness` for segments with sufficient history,
     - normalizes factors and writes `potency` ∈ [0,1] into latest `:SegmentState` and `:Segment.potency_latest`.

3. **Behavior matches theory**
   - The definitions of RoC, BoI, Amplification, Emotional/Psychological load, Gate Leverage, and Robustness correspond to the conceptual descriptions in the **Impact Factors for Structural Rogue Variables** section and the **Dynamics and extensibility** of MPG\_t.  [oai_citation:16‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

4. **Noetic integration hooks**
   - `:SegmentState.coherence` can be filled by an external Noetic process.
   - Mirror Core can query high‑potency/low‑coherence segments for meta‑control decisions in SORK‑N.

5. **Documentation**
   - This CR is saved as `docs/CR-003-Temporal-Potency-Noetic.md` alongside CR‑001 and CR‑002.

---

If you want, the next step (CR‑004) can be about **MUFS search + MPG‑Intuition** over this temporal MPG, wiring in restricted‑awareness conditions and storing MUFS results alongside `:SegmentState` to fully implement the MPG‑Intuition definitions and experimental protocol (Sections 5–6).  [oai_citation:17‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)
