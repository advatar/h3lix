Here we go — a set of concrete **Vision Pro / RealityKit entity designs** as change requests building on the previous Vision Pro architecture. These are about *how to actually structure the 3D “brain” scene in code*, wired to Somatic / Symbolic / Noetic / MPG / Rogue Variable / MUFS data from H3LIX.  [oai_citation:0‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  

---

## CR‑401 – Define Shared Visual State & Mapping Layer for VisionOS

**Status:** Proposed  
**Type:** Architecture / Data Model  
**Baseline:**  
- Vision Pro app design (H3LIXVisionApp, WindowGroup + ImmersiveSpace, RealityView).  
- Telemetry & API contracts (CR‑301/302/303: TelemetryEnvelope, MPG, RV, MUFS, SORK‑N loop).  [oai_citation:1‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  

### 1. Goal

Introduce a **Vision‑optimized visual state layer** that:

- Receives raw telemetry (Somatic, Symbolic, Noetic, MPG, Rogue Variables, MUFS, DecisionCycle).  [oai_citation:2‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  
- Reduces it to compact, frame‑friendly structs (floats, colors, small arrays).
- Feeds those structs into RealityKit entities (Helix, Halo, City, Ring, Overlays).

This keeps RealityKit update logic simple, minimizes allocations, and gives us one place to tune visual mappings (e.g., how valence → color, importance → scale).

### 2. New module: `H3LIXVisualState`

Create a Swift module or group:

```text
H3LIXVisualState/
  VisualMappings.swift
  HelixVisualState.swift
  HaloVisualState.swift
  MpgVisualState.swift
  SorkVisualState.swift
  OverlayVisualState.swift
```

### 3. Visual state structs

**3.1 Helix**

```swift
struct HelixRibbonState {
    var activity: Float        // 0..1, generic load
    var anomaly: Float         // 0..1, spikes / change‑points
    var uncertainty: Float     // 0..1, for fuzziness
}

struct HelixVisualState {
    var timePlaneHeight: Float // normalized 0..1, “now” position
    var somatic: HelixRibbonState
    var symbolic: HelixRibbonState
    var noetic: HelixRibbonState
}
```

Mapping examples (from H3LIX spec):

- `somatic.activity` ← norm of \(\hat{s}(t)\), smoothed.  [oai_citation:3‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  
- `somatic.anomaly` ← anomaly_score / change‑point flags.  
- `symbolic.activity` ← avg belief importance or prediction entropy reduction.  
- `noetic.activity` ← global coherence score; `noetic.uncertainty` ← |entropy_change|.  [oai_citation:4‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  

**3.2 Noetic Halo**

```swift
struct HaloBandState {
    var intensity: Float  // 0..1 coherence strength
    var turbulence: Float // 0..1 noise based on entropy change
}

struct HaloVisualState {
    var globalCoherence: Float   // 0..1
    var bands: [HaloBandState]   // one per freq band
}
```

**3.3 MPG City**

We don’t want full graphs here, only the subset in view:

```swift
struct MpgNodeInstance {
    var id: String
    var position: SIMD3<Float>
    var importance: Float  // 0..1 → height
    var confidence: Float  // 0..1 → brightness/opacity
    var valence: Float     // -1..1 → color hue
    var stability: Float   // 0..1 → base size
    var isRogueHotspot: Bool
    var isMufsElement: Bool
}

struct MpgEdgeInstance {
    var id: String
    var fromIndex: Int
    var toIndex: Int
    var strength: Float    // 0..1 → thickness
    var typeIndex: Int     // enum mapping to color palette
}

struct MpgVisualState {
    var level: Int
    var nodes: [MpgNodeInstance]
    var edges: [MpgEdgeInstance]
}
```

We assume layout (positions) is precomputed server‑side using MPG topology and lift operator as described in the paper.  [oai_citation:5‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  

**3.4 SORK‑N Ring & Overlays**

```swift
struct SorkPhaseState {
    var active: Bool
    var intensity: Float  // 0..1, recent activity
}

struct SorkVisualState {
    var cometAngle: Float         // radians
    var phases: [SorkPhaseState]  // S,O,R,K,N,S′ order
}

struct RogueOverlayState {
    var activeSegmentIds: [String]
}

struct MufsOverlayState {
    var hasMufs: Bool
    var affectedNodeIds: [String]
}
```

### 4. Mapping layer

Implement a `VisualStateBuilder` that:

- Subscribes to telemetry envelopes.
- Maintains a rolling buffer of latest Somatic / Symbolic / Noetic / MPG / RV / MUFS / DecisionCycle state.
- Produces `HelixVisualState`, `HaloVisualState`, `MpgVisualState`, `SorkVisualState`, `RogueOverlayState`, `MufsOverlayState` at ~30 Hz for the scene.

### 5. Acceptance criteria

- RealityKit entities do **not** parse raw telemetry; they only accept visual state structs.
- Visual mappings (valence→color, coherence→turbulence, etc.) live in one place (`VisualMappings.swift`).
- Running with a recorded session yields smooth, deterministic visuals when re‑played.

---

## CR‑402 – Implement `HelixEntity` & `BodyGhostEntity` (Somatic / Symbolic / Noetic)

**Status:** Proposed  
**Type:** 3D Entity Design  
**Baseline:** CR‑401 visual state layer; H3LIX architecture (Somatic, Symbolic, Noetic layers, Somatic signals).  [oai_citation:6‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  

### 1. Goal

Create a high‑performance RealityKit representation of:

- The **triple H3LIX** (Somatic, Symbolic, Noetic helices).
- A **ghost body + sensors** feeding into the Somatic ribbon.

### 2. `HelixEntity` design

**2.1 Structure**

```swift
final class HelixEntity: Entity, HasModel, HasAnchoring {
    let somaticRibbon = RibbonEntity(layerType: .somatic)
    let symbolicRibbon = RibbonEntity(layerType: .symbolic)
    let noeticRibbon  = RibbonEntity(layerType: .noetic)
    
    var timePlaneEntity: Entity    // thin glowing disc / plane
}
```

Each `RibbonEntity`:

- Uses a shared helix spline (e.g. parametric curve) with a GPU‑friendly extrusion.
- Has Material with layer‑specific color & pattern.

**2.2 Geometry**

- A base `MeshResource` for a gently twisted ribbon segment, instanced along the helix via transform array (e.g., 64 segments).
- For animation:
  - Uniforms/Material parameters for *local activity*, *anomaly*, *uncertainty*.
  - Vertex shader (or `MaterialCustomParameter`s) to slightly modulate thickness/scale along the path.

**2.3 Materials**

- Somatic: emissive cyan/teal; amplitude of pulsating emissive term ∝ `HelixRibbonState.activity`; quick “spark” flashes where `anomaly` > threshold.
- Symbolic: emissive amber; overlay a lightweight scrolling UV noise texture to evoke glyph flow; intensity ∝ activity.
- Noetic: emissive violet; sine‑based normal perturbation modulated by `uncertainty` to make pattern smooth vs. turbulent.

**2.4 Time plane**

- `timePlaneEntity` is a thin disc intersecting the helix:
  - Y‑position = helix height * `HelixVisualState.timePlaneHeight`.
  - Slight billboard face to user, glowing rim.

### 3. `BodyGhostEntity` design

**3.1 Purpose**

Visualize Somatic sensor locations and their connection into the Somatic ribbon using the Somatic layer definition (EDA, HRV, respiration, gaze, EEG, etc.).  [oai_citation:7‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  

**3.2 Structure**

```swift
final class BodyGhostEntity: Entity, HasAnchoring {
    struct Sensor {
        let name: String
        let localPosition: SIMD3<Float>
        let conduit: Entity      // ribbon from body -> somatic helix
    }
    
    var sensors: [Sensor] = []
    var bodyMesh: Entity       // transparent humanoid shell
}
```

- `bodyMesh`: low‑poly semi‑transparent torso/head, unlit material.
- Each `Sensor` conduit: thin tube mesh, using a spline from sensor position to a point on the Somatic ribbon.

**3.3 Mapping from Somatic telemetry**

For each `somatic_state`:

- Map chosen features or feature groups to sensor intensity (e.g., HRV → chest, EDA → palms, gaze → eyes).  [oai_citation:8‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  
- Update:
  - Sensor spheres emissive strength.
  - Conduit emissive pulses traveling toward the helix (animation speed ~window length).
- Change‑points:
  - Short, bright pulse along conduits + temporary thickening of the Somatic ribbon.

### 4. Update method

Add:

```swift
extension HelixEntity {
    func applyVisualState(_ state: HelixVisualState) { … }
}

extension BodyGhostEntity {
    func applySomaticState(_ state: SomaticStatePayload) { … }
}
```

RealityView’s `update` closure (or an async task) calls these with data from `H3LIXVisualState`.

### 5. Acceptance criteria

- Helix is drawn with ≤3 ribbons × ~64 segments each, instanced, staying under frame budget.
- Somatic / Symbolic / Noetic activity changes produce visible but smooth pulses and thickness shifts.
- Body ghost & sensor conduits react clearly to Somatic events (change‑points, anticipatory markers) without jitter.

---

## CR‑403 – Implement `NoeticHaloEntity` (Global Coherence Sphere)

**Status:** Proposed  
**Type:** 3D Entity Design  
**Baseline:** CR‑401 HaloVisualState; Noetic layer outputs (correlation matrices, entropy change, coherence spectra, intuitive accuracy).  [oai_citation:9‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  

### 1. Goal

Implement a performant, readable **Noetic halo** that visualizes:

- Overall coherence (smoothness).
- Band‑specific coherence (slices).
- Entropy change (turbulence).
- Intuitive accuracy pulses.

### 2. Entity structure

```swift
final class NoeticHaloEntity: Entity, HasModel {
    var surfaceEntity: ModelEntity
    var bandEntities: [ModelEntity]
}
```

- `surfaceEntity`: sphere mesh, medium tessellation.
- `bandEntities`: 3–5 thin spherical shells or rings stacked vertically.

### 3. Materials & shader parameters

Use an unlit or lightly‑lit custom material with:

- `globalSmoothness` ~ `HaloVisualState.globalCoherence`.
- `turbulence` ~ mean of `bands[i].turbulence`.
- For each band: store `intensity`.

Visual mapping:

- High coherence → low noise amplitude, slow scrolling ripples.
- Low coherence → higher spatial noise + subtle “grainy” distortion.
- Band intensity → emissive strength per band.

When `intuitive_accuracy_estimate.p_better_than_baseline` is high:

- Trigger a slow global “heartbeat” pulse:
  - Scale emissive up/down over ~1–2 seconds.
  - Optionally sync with Helix ribbons via shared parameter.

### 4. Update API

```swift
extension NoeticHaloEntity {
    func applyVisualState(_ state: HaloVisualState) { … }
}
```

Internal:

- Lerp between current and target params to avoid popping.
- Limit updates to ~30 Hz.

### 5. Acceptance criteria

- Noetic halo visibly differentiates high vs low coherence in a single glance.
- Halo updates do not cause noticeable frame drops (sphere tessellation and band counts tuned via Instruments).
- Intuitive bursts (high p_better_than_baseline) produce a subtle but globally perceivable pulse.

---

## CR‑404 – Implement `MpgCityEntity` (Mirrored Profile Graph “City” + Rogue & MUFS Overlays)

**Status:** Proposed  
**Type:** 3D Entity Design  
**Baseline:** CR‑401 MpgVisualState, RogueOverlayState, MufsOverlayState; MPG definition & segments / lift operator; Rogue Variables & MUFS formalism.  [oai_citation:10‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  

### 1. Goal

Create a scalable, visually readable RealityKit graph environment that:

- Renders **MPG nodes as buildings**, edges as roads/bridges, with multi‑level terraces.  [oai_citation:11‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  
- Highlights **Rogue Variables** as flaring neighborhoods.
- Supports **MUFS** split‑view with ghosted elements.

### 2. Entity structure

```swift
final class MpgCityEntity: Entity, HasAnchoring {
    private var nodeInstances: [MpgNodeInstance] = []
    private var edgeInstances: [MpgEdgeInstance] = []
    
    private var nodeModel: ModelEntity      // base building mesh
    private var nodeInstancer: InstancedEntity
    
    private var edgeModel: ModelEntity      // base edge/beam mesh
    private var edgeInstancer: InstancedEntity
    
    // Optional additional platforms for higher levels
    private var levelDecks: [ModelEntity] = []
}
```

Use **instancing**:

- `nodeInstancer` holds all building instances.
- `edgeInstancer` holds line/beam instances.
- Positions & per‑instance properties are passed from `MpgVisualState`.

### 3. Visual mapping

From `MpgNodeInstance`:

- `importance` → building height.
- `stability` → base width (stable nodes look broader).
- `confidence` → emissive intensity / window brightness.
- `valence` → hue along a blue–gray–orange gradient.  [oai_citation:12‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  
- `isRogueHotspot` → additional orange‑red overlay with rotating halo.
- `isMufsElement` → white outline + lower alpha for ghosted look.

Edges:

- `strength` → thickness and brightness.
- `typeIndex` → categorical color (causes, triggers, buffers, contradicts…).

Higher levels:

- If `level > 0`, cast certain nodes as **platforms** (meta‑segments), slightly elevated with a simplified mesh (discs or hex plates), with short “mini‑skyline” engraved.

### 4. Rogue Variable & MUFS overlays

**Rogue Variables**

- When `RogueOverlayState.activeSegmentIds` includes a node’s segment:
  - Node buildings: tint with bright orange/red additive emissive.
  - Add a `RogueHaloEntity` (thin ring, slow rotation) above local cluster.
  - Optionally spawn a vertical beam entity connecting to Helix origin.

**MUFS**

- In MUFS‑inspect mode:
  - For nodes in `MufsOverlayState.affectedNodeIds`, set `isMufsElement = true`.
  - If doing split city:
    - Duplicate a subset of nodes on one side with MUFS removed (no emissive, only ghost outlines).

### 5. Update API

```swift
extension MpgCityEntity {
    func applyVisualState(
        mpg: MpgVisualState,
        rogue: RogueOverlayState?,
        mufs: MufsOverlayState?
    ) { … }
}
```

Implementation notes:

- Detect node/edge additions vs updates to avoid recreating instance arrays when not needed.
- Use double‑buffering for per‑instance transforms & colors if we hit performance limits.

### 6. Acceptance criteria

- MPG city handles at least ~1–2k visible nodes at interactive frame rates (instancing required).
- Rogue Variable activation clearly pops visually without overwhelming the rest of the city.
- MUFS mode can show ghosted elements and/or split views with simple toggles.

---

## CR‑405 – Implement `SorkRingEntity` & Decision Cycle Visuals

**Status:** Proposed  
**Type:** 3D Entity Design  
**Baseline:** CR‑401 SorkVisualState; SORK‑N loop definition and Mirror Core description.  [oai_citation:13‡Symbiotic_human_AI_architecture.pdf](sediment://file_00000000a2f071f4a36d5a4040b12b83)  

### 1. Goal

Create a **control loop ring** around the helix that:

- Shows phase progression S → O → R → K → N → S′.
- Synchronizes with incoming `decision_cycle` telemetry.
- Ties visually into Helix, Halo, and City.

### 2. Entity structure

```swift
final class SorkRingEntity: Entity, HasModel {
    enum Phase: Int, CaseIterable { case S, O, R, K, N, SPrime }
    
    var ringModel: ModelEntity       // torus mesh
    var phaseMarkers: [ModelEntity]  // one per phase
    var cometEntity: ModelEntity     // small bright sphere
}
```

- `ringModel`: thin torus oriented around helix at mid‑height.
- `phaseMarkers`: small ticks or wedges at each phase, labeled via small floating TextEntities (`"S"`, `"O"`, etc.).

### 3. Visual mapping

From `SorkVisualState`:

- `cometAngle`: position the comet along the ring.
- `phases[i].active` & `intensity`:
  - Active phase marker glows brighter.
  - Ray/arc lines to relevant entities:
    - For S: subtle arcs to BodyGhost sensors / Somatic ribbon.
    - For O: arcs to Symbolic ribbon and selected MPG buildings.
    - For R: arc to a small “action glyph” entity attached above the city.
    - For K: arc downwards to an “outcome” marker in the city.
    - For N: arc up to Noetic halo; halo briefly spikes.
    - For S′: ripple emitted down Somatic ribbon.

To keep it efficient:

- Pre‑create a small pool of “arc” entities (thin curved quads) and reuse them with changing transforms/material intensity.

### 4. Update API

```swift
extension SorkRingEntity {
    func applyVisualState(_ state: SorkVisualState) { … }
}
```

Animation:

- Lerp comet angle over time so it appears to orbit smoothly.
- Fade in/out per‑phase glow instead of toggling bits.

### 5. Acceptance criteria

- With typical decision frequencies, comet motion remains smooth, not jittery.
- At any moment the active phase is obvious at a glance.
- Users can correlate SORK‑N activity with shifts in Helix / Halo / City behavior during demos.

---

If you like this direction, next step could be another CR series (e.g., **CR‑501+**) that focuses on **interaction & UX** specifically for Vision Pro (gaze/pinch node selection, “jump into a decision”, toggling MUFS split view, etc.), but with these four CRs you already have a pretty solid blueprint for the RealityKit scene graph and how it ties back to the H3LIX telemetry.
