**Change Request: CR‑008 – Meta‑Policies, Versioning & Trust Calibration for LAIZA/H3LIX**

---

## 1. Objective

Add a **meta‑policy layer** on top of the policy engine from CR‑007 so the system can:

1. Treat policies themselves as **first‑class objects** with versions, provenance, and evidence.  
2. Learn **when to trust** or **suspend** a given policy based on track record, context, Noetic coherence, and human overrides.  
3. Support **automatic branching / rollback** of policies under explicit governance rules.  
4. Integrate policy selection into the **Noetic (N → S′) step** of the SORK‑N loop, in line with the architecture’s emphasis on dynamic updates and governance.  [oai_citation:0‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

This extends the “governance and impact accounting” role of Rogue Variables and the **dynamics & extensibility** of MPGₜ (localize → roll up → restructure → project down) to *policies themselves*.  [oai_citation:1‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

---

## 2. Scope

### In scope

- Neo4j schema for **meta‑policies & versions**:
  - `:MetaPolicy`, `:PolicyVersion`, `:PolicyTrustSnapshot`.
- Meta‑level metrics:
  - “Policy Credibility Index” (trust score) analogous to Potency Index for structural RVs.  [oai_citation:2‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  
- Python components:
  - `MetaPolicyEngine` that:
    - picks **which policy** to use in a given context (including “no‑intervention baseline”),  
    - triggers versioning, rollback, or quarantine of policies.  
- API endpoints to:
  - query current active policy per (participant, group, task),  
  - inspect policy versions, trust scores, and audit logs.

### Out of scope

- Learning complicated ensembles of deep RL policies (we stick to bandit‑style or simple RL policies from CR‑007).
- UI for non‑technical stakeholders (we just expose APIs/data).

---

## 3. Theoretical grounding

Key connections to the paper:

- **Dynamics & extensibility of MPGₜ**: a time‑indexed hierarchy with updates that localize changes, roll them up, optionally restructure, then project them back down. Policies are now treated analogously to segments: we track their evolution over time and restructure them when performance shifts.  [oai_citation:3‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  
- **Impact factors & Potency Index**: we used RoC, BoI, Amplification, affective load, gate leverage, robustness to score Rogue structures. We’ll use analogous factors to score **policies**, but focused on their *behavioral impact* and *stability*.  [oai_citation:4‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  
- **Governance & impact accounting**: “All changes are validated, versioned, and narrated; the system tracks which events or chains most shaped structure and policy.” Meta‑policies operationalize this for the intervention policies themselves.  [oai_citation:5‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  
- **Noetic N → S′ step**: N sets meta‑adjustments (priors, thresholds, attention) before the next stimulus. Selecting *which policy family* applies is now one of those adjustments.  [oai_citation:6‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

---

## 4. Schema: treating policies as objects with versions

We already have:

- `:InterventionType`, `:Policy`, `:PolicyEpisode`, `:PolicyOutcome` from CR‑007.

CR‑008 adds:

### 4.1 Meta‑policy families

`(:MetaPolicy)` = a *family* of policies for a given domain (e.g. “Decision‑support for task T”, “Collective planning for group G”).

Properties:

```text
id: string
name: string
scope: "INDIVIDUAL" | "GROUP" | "BOTH"
description: string

risk_tier: "EXPERIMENTAL" | "SAFE" | "RESTRICTED"
status: "ACTIVE" | "PAUSED" | "DEPRECATED"

created_at: datetime
updated_at: datetime
owner: string          # human/compliance owner
notes: string
```

Relationships:

```text
(:MetaPolicy)-[:HAS_VERSION]->(:PolicyVersion)
(:MetaPolicy)-[:DEFAULT_POLICY]->(:PolicyVersion)    # current default
(:MetaPolicy)-[:FALLBACK_POLICY]->(:PolicyVersion)   # safe baseline
(:MetaPolicy)-[:RUNS_ON_GROUP]->(:Group)
(:MetaPolicy)-[:RUNS_ON_PARTICIPANT]->(:Participant)
```

### 4.2 Policy versions

Instead of mutating a `:Policy` in place, we snapshot parameters as `:PolicyVersion`.

Properties:

```text
id: string
policy_id: string       # points to logical policy (e.g., "ContextualBandit_v1")
version_tag: string     # e.g. "v1.0.3"
created_at: datetime
parent_version_id: string | null

hyperparams: map        # alpha, exploration rate, etc.
parameters_blob: string # serialized bandit weights/theta, hashed
context_dim: int

status: "CANDIDATE" | "LIVE" | "ROLLED_BACK" | "DEPRECATED"
reasoning: string       # R(v)-style explanation for why this version exists
```

Relationships:

```text
(:PolicyVersion)-[:OF_POLICY]->(:Policy)
(:PolicyVersion)-[:PREVIOUS_VERSION]->(:PolicyVersion)
(:PolicyVersion)-[:EVALUATED_IN]->(:PolicyEpisode)
```

### 4.3 Policy trust snapshots

We mirror `:SegmentState` with `:PolicyTrustSnapshot` to model policy dynamics over time (policyₜ).

Properties:

```text
id: string
policy_version_id: string
t: float | int         # time index, epoch, or training step

reward_mean: float
reward_std: float
n_episodes: int

override_rate: float      # human override fraction
safety_flags: int         # # of safety triggers

delta_coherence_mean: float
delta_accuracy_mean: float
delta_calibration_mean: float

trust_score: float        # 0..1, meta‑Potency-like
notes: string
created_at: datetime
```

Relationships:

```text
(:PolicyVersion)-[:HAS_TRUST_STATE]->(:PolicyTrustSnapshot)
```

Conceptually, this is **policy‑level MPGₜ** (time‑indexed) with a single scalar trust metric analogous to segment Potency, but for “how reliable/useful is this policy version in this context?”.

---

## 5. Meta‑metrics: “Policy Credibility Index”

We define a **Policy Credibility Index** (PCI) inspired by Potency factors (RoC, BoI, amplification, affective load, gate leverage, robustness).  [oai_citation:7‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

For each policy version v, from its episodes & outcomes we compute:

- **Performance Stability**: mean & variance of rewards over last K episodes.  
- **Safety & Override metrics**:
  - override rate (human overrides / episodes),
  - count of safety flags (e.g., triggers where coherence dropped below threshold).  
- **Coherence impact**: mean Δcoherence (C_after − C_before).  
- **Outcome impact**: mean Δaccuracy, Δcalibration.  
- **Context coverage**:
  - diversity of contexts where v has been tried (entropy over context clusters).  

We then define raw factors:

```text
Growth (RoC_p)      = slope of reward_mean over recent snapshots
Breadth (BoI_p)     = context_coverage * n_episodes
Amplification_p     = +1 if policy interacts with high-potency segments frequently
Safety_p            = 1 - override_rate - safety_penalty
Robustness_p        = (1 - reward_std) * (episodes_normalized)
Coherence_p         = mean positive Δcoherence clipped at 0
```

Normalize each to [0,1] (as in CR‑003) and compute:

```text
PCI(v) = w_growth * Growth_norm
       + w_breadth * BoI_norm
       + w_amp    * Amplification_norm
       + w_safe   * Safety_norm
       + w_rob    * Robustness_norm
       + w_coh    * Coherence_norm
```

Store PCI in `PolicyTrustSnapshot.trust_score`, and roll latest value up to `PolicyVersion.trust_score_latest`.

Weights start conservative, e.g.:

```text
w_growth = 0.1
w_breadth = 0.15
w_amp = 0.1
w_safe = 0.25
w_rob = 0.2
w_coh = 0.2
```

So **safety & robustness matter more than raw performance**.

---

## 6. MetaPolicyEngine: choosing & managing policies

### 6.1 Runtime policy selection

We introduce `MetaPolicyEngine` which:

- Given **trial context** x and a MetaPolicy M, selects a `PolicyVersion` to use (or falls back to “no intervention”).  
- Uses PCI + simple bandit over policies.

Sketch:

```python
# policies/meta_policy_engine.py
from dataclasses import dataclass
import numpy as np
from typing import List, Dict

@dataclass
class PolicyVersionInfo:
    id: str
    trust_score: float
    status: str          # LIVE / CANDIDATE / ROLLED_BACK
    risk_tier: str       # from MetaPolicy
    context_embed: np.ndarray  # optional embedding of where it's been used

class MetaPolicyEngine:
    def __init__(self, meta_policy_id: str, db):
        self.meta_policy_id = meta_policy_id
        self.db = db
        self.policy_versions: Dict[str, PolicyVersionInfo] = {}
        self._load_versions()

    def _load_versions(self):
        # query Neo4j for versions + latest trust_score
        ...

    def select_version(self, x: np.ndarray) -> PolicyVersionInfo:
        """
        Conservative selection:
        - filter to LIVE versions with adequate trust_score
        - optionally include a SAFE baseline and 'NO_INTERVENTION'
        - pick argmax of (trust_score + small exploration bonus)
        """
        candidates = [
            v for v in self.policy_versions.values()
            if v.status == "LIVE" and v.trust_score >= 0.3
        ]
        if not candidates:
            return self._safe_fallback()

        # small exploration for candidates with less usage
        scores = []
        for v in candidates:
            exploration = 0.05  # or function of n_episodes
            scores.append(v.trust_score + exploration)

        return candidates[int(np.argmax(scores))]

    def _safe_fallback(self) -> PolicyVersionInfo:
        # returns baseline policy or 'NO_INTERVENTION'
        ...
```

Mirror Core calls `MetaPolicyEngine.select_version` before picking a concrete **intervention** via the CR‑007 bandit.

### 6.2 Versioning, branching & rollback

We also add methods:

- `spawn_candidate_version(parent_version_id, changes)`:
  - copy bandit weights/hyperparams,
  - adjust learning rate, exploration, or action set,
  - create `:PolicyVersion` with status `"CANDIDATE"` and `parent_version_id` set.  

- `promote_version(version_id)`:
  - mark version as `"LIVE"`,
  - update `:MetaPolicy-[:DEFAULT_POLICY]->(:PolicyVersion)` to point to it.  

- `rollback_version(version_id)`:
  - mark version as `"ROLLED_BACK"`,
  - reset default to previous safe version or fallback baseline.

Promotion/rollback conditions:

- triggered when **PCI(v)** crosses thresholds:
  - below `PCI_min` for N episodes → quarantine (PAUSED) or rollback.  
  - above `PCI_promote` for N episodes in a limited context → promotion candidate.

These changes follow the MPGₜ pattern: **localize** poor behavior to a version, **roll up** to MetaPolicy state, optionally **restructure** policy tree (branch/rollback), then **project down** by changing which version is used in S′.  [oai_citation:8‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

---

## 7. Noetic integration: policy selection as a metacognitive action

The Noetic layer’s job is to monitor coherence and adjust priors, attention, thresholds, and gating.  [oai_citation:9‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

CR‑008 adds:

- `Noetic.compute_meta_context(trial)`:
  - including current C(t), entropy‑change, presence of high‑Potency RVs, trial awareness type (FULL/IU/PU).
- `MetaPolicyEngine.select_version(x_noetic)`:
  - uses this meta‑context to decide:
    - use **no policy** (when coherence is high and stable and there are no dangerous RVs),
    - use **conservative policy** (when coherence is low and RVs are high‑potency),
    - allow **candidate experimental policy** in low‑risk regimes.

This ensures the policy engine itself is **inside** the SORK‑N loop rather than bypassing Noetic.

---

## 8. API extensions

Extend the API:

```python
# api/meta_policy_api.py
from fastapi import APIRouter
from pydantic import BaseModel

router = APIRouter(prefix="/meta_policy", tags=["meta_policy"])

@router.get("/{meta_policy_id}/status")
def get_meta_policy_status(meta_policy_id: str):
    # returns current default version, fallback, trust scores
    ...

@router.get("/{meta_policy_id}/versions")
def list_versions(meta_policy_id: str):
    # returns all PolicyVersion nodes with trust scores, statuses
    ...

class VersionControl(BaseModel):
    meta_policy_id: str
    version_id: str
    action: str           # "PROMOTE" | "ROLLBACK" | "PAUSE"

@router.post("/version_control")
def version_control(vc: VersionControl):
    # apply governance-approved change in Neo4j
    ...
```

And optionally:

- `GET /meta_policy/{id}/episodes` – audit trail of interventions & outcomes.

---

## 9. Governance & human oversight

To match the paper’s emphasis on **governance and impact accounting**:  [oai_citation:10‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

- **Human approval required** for:
  - creating new MetaPolicies,  
  - promoting candidate versions to LIVE,  
  - enabling interventions on high‑affective‑load segments.  
- Automatic triggers (rollback, pause) can be applied when:
  - PCI < `PCI_critical` for many episodes,  
  - safety flags exceed threshold,  
  - override rate skyrockets.  
- Every version change records:
  - who approved,
  - why (R‑style reasoning),
  - what supporting evidence (metrics, plots, notes).

This keeps the entire meta‑policy stack fully auditable and consistent with the MPG’s evidence & reasoning provenance model.  [oai_citation:11‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

---

## 10. How to run CR‑008 end‑to‑end

1. **Schema migration**
   - Add `:MetaPolicy`, `:PolicyVersion`, `:PolicyTrustSnapshot` with constraints.
   - Add relationships from MetaPolicy to PolicyVersion and policies to episodes.

2. **Metrics job**
   - Implement a periodic job (e.g., `scripts/policy_trust_update.py`) that:
     - reads recent `:PolicyEpisode` + `:PolicyOutcome`,
     - computes raw metrics,
     - writes `:PolicyTrustSnapshot` and updates `PolicyVersion.trust_score_latest`.

3. **MetaPolicyEngine**
   - Implement class with:
     - `select_version(context)`,
     - `spawn_candidate_version(...)`,
     - `promote_version`, `rollback_version`.
   - Integrate into Mirror Core’s N → S′ step.

4. **API**
   - Add `/meta_policy/*` endpoints for status & version control.

5. **Pilot**
   - Run policy engine in **shadow mode** first (suggestions only) while PCI is tracked.  
   - Once stable, allow it to influence interventions under a safe MetaPolicy with clear fallback.

---

## 11. Acceptance criteria

CR‑008 is complete when:

1. **Meta‑policy graph**
   - Neo4j contains `:MetaPolicy` nodes with connected `:PolicyVersion` and `:PolicyTrustSnapshot` nodes.
   - Each active policy has at least one trust snapshot with a computed `trust_score`.

2. **MetaPolicyEngine**
   - Given a context, it can:
     - select a safe `PolicyVersion`,
     - fall back to a baseline when trust is low or unknown.  
   - It can spawn candidate versions and mark them appropriately.

3. **Noetic integration**
   - Mirror Core uses `MetaPolicyEngine` in N → S′, with policy selection influenced by Noetic coherence and active RV/ Potency information.  [oai_citation:12‡Symbiotic_human_AI_architecture.pdf](sediment://file_000000000db071f49f637b00e8081106)  

4. **Governance**
   - Promotion/rollback of policy versions is logged in Neo4j with reasoning and metrics.
   - High override / low trust automatically results in policy quarantine or rollback.

5. **Empirical sanity**
   - On at least one task, meta‑policy management:
     - prevents obviously degraded policies from staying live,
     - prefers versions with better safety and coherence impact,
     - leaves a clear, queryable audit trail of version changes and their rationales.

---

If you’d like to push this even further, a **CR‑009** could focus on **formal evaluation & benchmarking**: define quantitative test suites and benchmarks (e.g., ablation experiments over RVs, coherence, MUFS, policies) to systematically compare H3LIX/LAIZA to baseline architectures across tasks, including pre‑registered protocols for intuition and coherence tests.
